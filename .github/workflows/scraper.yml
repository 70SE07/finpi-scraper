name: Scraper Run

on:
  schedule:
    # Запуск каждый день в 6:00 UTC (9:00 по Киеву)
    - cron: '0 6 * * *'
  workflow_dispatch:
    inputs:
      site_name:
        description: 'Site to scrape (rost, rozetka, tesco)'
        required: false
        default: 'rost'
        type: choice
        options:
        - rost
        - rozetka
        - tesco
        - all

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        cd finpi_scraper
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Download spaCy models
      run: |
        cd finpi_scraper
        python -m spacy download en_core_web_sm
        python -m spacy download de_core_news_sm
        python -m spacy download ru_core_news_sm
        python -m spacy download uk_core_news_sm
    
    - name: Download NLTK data
      run: |
        cd finpi_scraper
        python -c "import nltk; nltk.download('stopwords'); nltk.download('punkt')"
    
    - name: Run scraper
      env:
        SCRAPERAPI_KEY: ${{ secrets.SCRAPERAPI_KEY }}
      run: |
        cd finpi_scraper
        if [ "${{ github.event.inputs.site_name }}" = "all" ] || [ -z "${{ github.event.inputs.site_name }}" ]; then
          python main.py
        else
          python main.py ${{ github.event.inputs.site_name }}
        fi
    
    - name: Upload results
      uses: actions/upload-artifact@v3
      with:
        name: scraped-data-${{ github.run_number }}
        path: finpi_scraper/output/
        retention-days: 30
    
    - name: Upload logs
      uses: actions/upload-artifact@v3
      with:
        name: scraper-logs-${{ github.run_number }}
        path: finpi_scraper/scraper.log
        retention-days: 7
