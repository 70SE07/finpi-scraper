#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞ 'other' –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
–Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤.
"""

import json
import os
import sys
from collections import defaultdict
import logging

# --- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ ---
try:
    # –ü–æ–ø—ã—Ç–∫–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞, –∫–æ–≥–¥–∞ —Å–∫—Ä–∏–ø—Ç - —á–∞—Å—Ç—å –ø–∞–∫–µ—Ç–∞
    from .categorization import categorize_product
    from .lemmatizer import lemmatize_text # –ù—É–∂–µ–Ω –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —è–∑—ã–∫–∞
except ImportError:
    # –§–æ–ª–±—ç–∫ –¥–ª—è –ø—Ä—è–º–æ–≥–æ –∑–∞–ø—É—Å–∫–∞: –¥–æ–±–∞–≤–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ sys.path
    sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
    from utils.categorization import categorize_product
    from utils.lemmatizer import lemmatize_text

def load_keywords(keywords_file):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ñ–∞–π–ª–∞."""
    if not os.path.exists(keywords_file):
        logging.error(f"–§–∞–π–ª –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {keywords_file}")
        return None
    try:
        with open(keywords_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {e}")
        return None

def load_products_from_file(file_path):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–æ–≤–∞—Ä—ã –∏–∑ —Ñ–∞–π–ª–∞."""
    if not os.path.exists(file_path):
        # –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è —Å–∏—Ç—É–∞—Ü–∏—è, –µ—Å–ª–∏ —Ñ–∞–π–ª –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –µ—â–µ –Ω–µ —Å–æ–∑–¥–∞–Ω
        logging.warning(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π: {os.path.basename(file_path)}")
        return []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return [line.strip() for line in f.readlines() if line.strip()]
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")
        return []

def save_products_to_file(products, file_path):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ –≤ —Ñ–∞–π–ª, –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—è –µ–≥–æ."""
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(products) + '\n')
        return True
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª {file_path}: {e}")
        return False

def append_products_to_file(products, file_path):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Ç–æ–≤–∞—Ä—ã –≤ —Ñ–∞–π–ª, –∏–∑–±–µ–≥–∞—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤."""
    existing_products = set(load_products_from_file(file_path))
    new_products = [p for p in products if p not in existing_products]
    
    if not new_products:
        return 0
        
    all_products = sorted(list(existing_products.union(set(new_products))))
    save_products_to_file(all_products, file_path)
    return len(new_products)

def redistribute_products(other_file_path, keywords_file, lang='uk'):
    """
    –ü–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–æ–≤–∞—Ä—ã –∏–∑ —Ñ–∞–π–ª–∞ OTHER.
    """
    logging.info("üîÑ –ù–∞—á–∏–Ω–∞—é –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ OTHER...")
    
    keywords_data = load_keywords(keywords_file)
    if not keywords_data:
        return False

    products = load_products_from_file(other_file_path)
    if not products:
        logging.warning("–§–∞–π–ª OTHER –ø—É—Å—Ç –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω. –ù–µ—á–µ–≥–æ –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—Ç—å.")
        return False

    logging.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ {os.path.basename(other_file_path)}")

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ç–æ–≤–∞—Ä—ã –ø–æ –Ω–æ–≤—ã–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    newly_categorized = defaultdict(list)
    remaining_in_other = []
    
    for product in products:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Å —É—á–µ—Ç–æ–º —è–∑—ã–∫–∞
        subcategory = categorize_product(product, keywords_data, lang)
        if subcategory != 'other':
            newly_categorized[subcategory].append(product)
        else:
            remaining_in_other.append(product)

    if not newly_categorized:
        logging.info("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å –Ω–æ–≤—ã–º–∏ –∫–ª—é—á–∞–º–∏.")
        return True

    logging.info("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è:")
    total_redistributed = 0
    output_dir = os.path.dirname(other_file_path)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä "rozetka_alcohol_"
    base_filename = os.path.basename(other_file_path).replace('_other.txt', '')

    for subcategory, prods in newly_categorized.items():
        total_redistributed += len(prods)
        logging.info(f"  -> –ö–∞—Ç–µ–≥–æ—Ä–∏—è '{subcategory}': {len(prods)} —Ç–æ–≤–∞—Ä–æ–≤")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
        target_filename = f"{base_filename}_{subcategory}.txt"
        target_filepath = os.path.join(output_dir, target_filename)
        
        added_count = append_products_to_file(prods, target_filepath)
        logging.info(f"     –î–æ–±–∞–≤–ª–µ–Ω–æ {added_count} –Ω–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –≤ {target_filename}")

    # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª OTHER
    logging.info(f"üóëÔ∏è –û–±–Ω–æ–≤–ª—è—é {os.path.basename(other_file_path)}...")
    save_products_to_file(remaining_in_other, other_file_path)
    
    logging.info(f"\nüéâ –ü–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    logging.info(f"üì¶ –í—Å–µ–≥–æ –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–æ: {total_redistributed} —Ç–æ–≤–∞—Ä–æ–≤.")
    logging.info(f"üìÅ –û—Å—Ç–∞–ª–æ—Å—å –≤ OTHER: {len(remaining_in_other)} —Ç–æ–≤–∞—Ä–æ–≤.")
    
    return True

def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏.
    """
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M')
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—è —Å–∫—Ä–∏–ø—Ç–∞
    script_dir = os.path.dirname(os.path.abspath(__file__))
    base_dir = os.path.join(script_dir, '..') # finpi_scraper/

    # TODO: –°–¥–µ–ª–∞—Ç—å –≤—ã–±–æ—Ä —Ñ–∞–π–ª–∞ –±–æ–ª–µ–µ –≥–∏–±–∫–∏–º, —á–µ—Ä–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    other_file = os.path.join(base_dir, "output/GOODS/GROCERIES/BEVERAGES/rozetka_alcohol_other.txt")
    keywords_file = os.path.join(base_dir, "keywords/alcohol_keywords.json")
    
    # TODO: –û–ø—Ä–µ–¥–µ–ª—è—Ç—å —è–∑—ã–∫ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –∏–ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    lang = 'uk' 
    
    redistribute_products(other_file, keywords_file, lang)

if __name__ == "__main__":
    main()